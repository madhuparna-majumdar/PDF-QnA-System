# PDF-QnA-System

This project is a Question Answering (QA) system built using LangChain, Amazon Bedrock, and FAISS. It extracts both text and images from PDF documents—such as printer manuals—using PyMuPDF, then encodes the images in base64 format. The extracted text is chunked and embedded using Amazon Titan Embeddings (amazon.titan-embed-text-v1), and stored in a FAISS vector store for efficient semantic similarity search. When a user submits a query, the system retrieves the most relevant text chunks using FAISS and constructs a prompt that includes the corresponding images (embedded as base64). This prompt is passed to Claude (anthropic.claude-v2) via Amazon Bedrock to generate context-aware answers. In Jupyter Notebook, the system also decodes and renders relevant images inline alongside the response. The result is an end-to-end RAG pipeline capable of delivering accurate and visually-supported answers from technical documents.
