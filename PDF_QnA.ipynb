{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090be717-b698-447a-9a8a-92590799c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install faiss-cpu    # or faiss-gpu if using GPU\n",
    "%pip install boto3\n",
    "%pip install langchain-community\n",
    "%pip install PyMuPDF  # for text + image extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c86e72f-6d46-4d0d-b9ea-fdc6a011a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import base64\n",
    "from IPython.display import display, Image\n",
    "\n",
    "def extract_text_and_images(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text()\n",
    "        images = []\n",
    "\n",
    "        for img in page.get_images(full=True):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_b64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "            images.append({\n",
    "                \"base64\": image_b64,\n",
    "                \"ext\": base_image[\"ext\"]\n",
    "            })\n",
    "\n",
    "        pages.append({\n",
    "            \"page_number\": i,\n",
    "            \"text\": text,\n",
    "            \"images\": images\n",
    "        })\n",
    "    return pages\n",
    "\n",
    "\n",
    "def display_base64_image(image_base64, image_ext):\n",
    "  image_bytes = base64.b64decode(image_base64)\n",
    "  display(Image(data=image_bytes, format=image_ext))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a38178-08eb-4eed-8b14-c3ef04a6cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "def create_vector_store(pages):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    docs = []\n",
    "\n",
    "    for page in pages:\n",
    "        for chunk in text_splitter.split_text(page[\"text\"]):\n",
    "            metadata = {\"page_number\": page[\"page_number\"]}\n",
    "            docs.append(Document(page_content=chunk, metadata=metadata))\n",
    "\n",
    "    embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\")\n",
    "    vector_store = FAISS.from_documents(docs, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "def retrieve_top_chunks(vector_store, query, k=3):\n",
    "    return vector_store.similarity_search(query, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dbe238f-9ad2-4c68-bdbc-88b6eb3b8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_prompt(query, documents, pages):\n",
    "    context = \"\"\n",
    "    added_pages = set()\n",
    "\n",
    "    for doc in documents:\n",
    "        page_num = doc.metadata[\"page_number\"]\n",
    "        context += f\"Page {page_num}:\\n{doc.page_content}\\n\\n\"\n",
    "\n",
    "        if page_num not in added_pages:\n",
    "            images = pages[page_num][\"images\"]\n",
    "            for img in images:\n",
    "                context += f\"![Image_Page_{page_num}](data:image/{img['ext']};base64,{img['base64']})\\n\\n\"\n",
    "            added_pages.add(page_num)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a helpful assistant answering questions from a printer manual.\n",
    "Use the following context to answer:\n",
    "\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434305ab-328a-4bc7-92f9-8dd8c5b196a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from extract_pdf import extract_text_and_images\n",
    "#from vector_store import create_vector_store, retrieve_top_chunks\n",
    "#from prompt_builder import build_prompt\n",
    "\n",
    "from langchain.llms import Bedrock\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"XXXXXXXXXX\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"XXXXXXXXXXXXXXXXXX\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n",
    "\n",
    "def main():\n",
    "    # Step 1: Load PDF\n",
    "    print(\"üîç Extracting text and images...\")\n",
    "    file_path = \"HP_printer_manual.pdf\" \n",
    "    pages = extract_text_and_images(file_path)\n",
    "\n",
    "    # Step 2: Vector Store\n",
    "    print(\"üì¶ Creating vector store...\")\n",
    "    vector_store = create_vector_store(pages)\n",
    "\n",
    "    # Step 3: Chat Loop\n",
    "    llm = Bedrock(model_id=\"anthropic.claude-v2\")\n",
    "    print(\"ü§ñ Ask me anything about the printer manual!\")\n",
    "\n",
    "    while True:\n",
    "        query = input(\"\\nUser: \")\n",
    "        if query.lower() in [\"exit\", \"quit\"]:\n",
    "            break\n",
    "\n",
    "        docs = retrieve_top_chunks(vector_store, query)\n",
    "        prompt = build_prompt(query, docs, pages)\n",
    "        response = llm(prompt)\n",
    "        print(\"\\nAssistant:\", response)\n",
    "\n",
    "     # Display images from relevant pages\n",
    "        displayed_pages = set()\n",
    "        for doc in docs:\n",
    "          page_num = doc.metadata[\"page_number\"]\n",
    "          if page_num not in displayed_pages:\n",
    "            images = pages[page_num][\"images\"]\n",
    "            for img in images:\n",
    "                print(f\"\\nüñºÔ∏è Displaying image from Page {page_num}\")\n",
    "                display_base64_image(img[\"base64\"], img[\"ext\"])\n",
    "            displayed_pages.add(page_num)\n",
    "\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(0.5)         \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eff8d8-c65f-47be-bd32-9a05f1a9a0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
